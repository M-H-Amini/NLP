{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-TwitterLogisticRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYJpsjH8nluG",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "\n",
        "# Twitter Sentiment Analysis Using Logistic Regression\n",
        "\n",
        "# Mohammad Hossein Amini\n",
        "\n",
        "In this project, we will do sentiment analysis on some tweets using **Logistic Regression**.\n",
        "\n",
        "After preprocessing each tweet, we'll count frequency of its words in both positive and negative tweets. So for each tweet, there are 2 features: Positive and Negative frequencies. we'll use these feature vectors to classify tweets!\n",
        "\n",
        "we would implement logistic regression using **keras**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6g3dUISdojD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk                                  \n",
        "from nltk.corpus import twitter_samples      \n",
        "import matplotlib.pyplot as plt              \n",
        "import numpy as np       \n",
        "import keras\n",
        "from utils import process_tweet, build_freqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEMoAHOLok46",
        "colab_type": "text"
      },
      "source": [
        "Let's download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWt5MD49eEMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1CIOCUkoo0z",
        "colab_type": "text"
      },
      "source": [
        "Now we would create some lists containing our tweets as strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQLUTVQheP1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select the lists of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# concatenate the lists, 1st part is the positive tweets followed by the negative\n",
        "tweets = all_positive_tweets + all_negative_tweets\n",
        "\n",
        "# let's see how many tweets we have\n",
        "print(\"Number of tweets: \", len(tweets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RlF0eB4eW6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.append(np.ones((len(all_positive_tweets))), np.zeros((len(all_negative_tweets))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIbBX1Ozo3FO",
        "colab_type": "text"
      },
      "source": [
        "Let's count frequency of each word in both positive and negative tweets. We'd use ```build_freqs``` function for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKkqi24Wea3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create frequency dictionary\n",
        "freqs = build_freqs(tweets, labels)\n",
        "\n",
        "# check data type\n",
        "print(f'type(freqs) = {type(freqs)}')\n",
        "\n",
        "# check length of the dictionary\n",
        "print(f'len(freqs) = {len(freqs)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3A3RDGkpMPP",
        "colab_type": "text"
      },
      "source": [
        "Time for preprocessing and extracting features! ```extractFeatures``` would get a tweet and returns the 2-element feature vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rljh26Dved11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractFeatures(tweet):\n",
        "  tweet = process_tweet(tweet)\n",
        "  pos, neg = 0, 0\n",
        "  for word in tweet:\n",
        "    pos += freqs.get((word, 1.), 0)\n",
        "    neg += freqs.get((word, 0.), 0)\n",
        "  feature_vec = np.array([pos, neg])\n",
        "  return feature_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfCOhSqcfrRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 15\n",
        "print(tweets[index])\n",
        "print(extractFeatures(tweets[index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ac1yFZwpefR",
        "colab_type": "text"
      },
      "source": [
        "Splitting data into train and test now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WttYTI-xfyTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tweets = all_positive_tweets[:4000] + all_negative_tweets[:4000]\n",
        "train_labels = [1. for i in range(4000)] + [0. for i in range(4000)]\n",
        "test_tweets = all_positive_tweets[4000:] + all_negative_tweets[4000:]\n",
        "test_labels = [1. for i in range(1000)] + [0. for i in range(1000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDMq-6xmgFyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_tweets), len(test_tweets))\n",
        "print(len(train_labels), len(test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IMdKXRIpiMr",
        "colab_type": "text"
      },
      "source": [
        "We'd have some numpy arrays to keep training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npK6ab7ogcVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.zeros((len(train_tweets), 2))\n",
        "y_train = np.array(train_labels)\n",
        "X_test = np.zeros((len(test_tweets), 2))\n",
        "y_test = np.array(test_labels)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY5CSbDMg2yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(X_train.shape[0]):\n",
        "  X_train[i] = extractFeatures(train_tweets[i])\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "  X_test[i] = extractFeatures(test_tweets[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVWvZs4nhKso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train[15], y_train[15])\n",
        "print(X_train[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv14YFZ4poUW",
        "colab_type": "text"
      },
      "source": [
        "Let's do the logistic regression now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tvdWnXhSUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([keras.layers.Dense(1, activation='sigmoid', input_shape=(2,))])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsQ4uXqqht57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuFWxeWViXbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c0e5roJlfXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print([model.weights[i].numpy() for i in range(2)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAKedk7jptDQ",
        "colab_type": "text"
      },
      "source": [
        "Testing and seeing our brilliant result would be so fun."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jV1PLMimCL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 1500\n",
        "print(model.predict(X_test[index:index+1, :]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_c98YvSp2AO",
        "colab_type": "text"
      },
      "source": [
        "And finally, we would create a ```classify``` function which gets a string and classifies it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E18qchXp-KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(tweet):\n",
        "  tweet = extractFeatures(tweet)\n",
        "  return model.predict(tweet[np.newaxis, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHDGgzJqPDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg = 'I hated it!'\n",
        "pos = 'It was an honor to view this great one!'\n",
        "print(classify(neg), classify(pos))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}